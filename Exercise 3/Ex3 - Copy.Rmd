---
title: "ASML EXAM Exercise 3"
output: html_notebook
header-includes:
   - \usepackage{bbm}
---

```{r warning=FALSE}
library(ggplot2)
library(tidyverse)
```

```{r}
load(file = "test2.RData")
dat=data2
```

```{r}
head(dat)
```


### <u>(a) Perform the multiple regression model and analyse all the outputs that are available.</u>

```{r}
LM = lm(Y~.,data = dat)
```

```{r}
plot(LM,3)
```

```{r}
plot(LM,2)
```

```{r}
summary(LM)
```

- Adjusted R-squared is not close to 1: the linear model will not be able to explain all the variance
- noise is gaussian: following staright line on QQplot
- we can see also that noise is not homoscedastic: points are not spread equally on standardized residuals vs fitted values

### <u>(b) Is this model interesting?</u>

Model is not interresting, noise assumptions are not satisfied and Adjusted R-squared is not good.

### <u>(c) Perform a non-linear model and analyse it.</u>

```{r}
BestTree <- function(X,Y){
  # package about CART
  library(rpart)
  # generate max tree
  TreeMAX = rpart(Y~.,data=X,control = rpart.control(cp=10^-9,minsplit=2))
  # find cp corresponding to OneSE
  CPs=TreeMAX$cptable
  smallest_xerror = which(CPs[,'xerror'] == min(CPs[,'xerror']))
  oneSE = CPs[smallest_xerror,'xerror']+CPs[smallest_xerror,'xstd']
  CPBestTree = head(CPs[CPs[,'xerror']<=oneSE,],1)[,'CP']
  # Prune Tree and return best tree
  BestTree = prune(TreeMAX,cp=CPBestTree)
}

X = dat[,-1]
Y = dat[,1]

Tree = BestTree(X,Y)
plot(Tree)
text(Tree)
```

### <u>(d) What are the variables that are really connected to the response variable?</u>

```{r}
printcp(Tree)
```

X1, X4 and X7 are the variables used in tree construction, they are really connected to response variable.
