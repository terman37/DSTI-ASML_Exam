---
title: "ASML EXAM Exercise 4"
output: html_notebook
header-includes:
   - \usepackage{bbm}
---

```{r warning=FALSE}
library(ggplot2)
library(tidyverse)
library(car)
```


Three teams take turns on a production line (morning, afternoon, night). They use four work stations denoted A,B,C and D. During one month, we count the number of defective parts according to the team and the work station. Here is the observations:

```{r}
dat = data.frame("Team"=factor(c(rep("Morning",4),rep("Afternoon",4),rep("Night",4))),
           "Workstation"=factor(c(rep(c("A","B","C","D"),3))),
           "nb_defects"=c(26,13,35,6,18,17,31,2,31,24,33,4))

head(dat)
attach(dat)
```

We would like to analyse this table with a analysis of variance with two factors

### <u>(a) For the moment, we analyse the variables team and work station separately.</u>

#### i. Can we say that the performance are not the same with respect to the team?

```{r}
boxplot(nb_defects~Team)
```

--> is there a link between team (X) and nb of defects (Y)

- Test model = Yi = µ + ai + εi,j, H0: all ai are equals / H1: at least one ai is different

- p-value > 0.05: we do not reject H0, we cannot say the performance is different among teams

```{r}
mod=lm(nb_defects~Team)
Anova(mod)
```


#### ii. Can we say that the difficulties associated to each work station are not the same?

```{r}
boxplot(nb_defects~Workstation)
```

--> is there a link between workstation (X) and nb of defects (Y)

- Test model = Yi = µ + ai + εi,j, H0: all ai are equals / H1: at least one ai is different

- p-value < 0.05: we reject H0, nb of defect is dependent on workstation (at least one)

```{r}
mod=lm(nb_defects~Workstation)
Anova(mod)
```

### <u>(b) Now we take into account both variables in the same time. At first we consider the additive model Yi,j = µ + ai + bj + εi,j where the εi,j are i.i.d. random variables whose distribution is N (0, σ2).</u>

```{r}
LM=lm(nb_defects~Team+Workstation)
```

#### i. How to validate the use of the additive model?

Assumptions on the noise are ok
We have to check if there is an influence of the cross effect Team*Workstation

```{r}
cLM = lm(nb_defects~Team+Workstation+Team*Workstation)
anova(cLM)
```

As there is only one observation for each cross effect parameter, we are not able to compute the F tests

Check graphically that lines are parralel... no easy to see...

```{r}
interaction.plot(Team,Workstation,nb_defects)
```

Another method is to use Tukey's test of additivity, described [here](https://en.wikipedia.org/wiki/Tukey%27s_test_of_additivity)
and implemented in R using additivityTests library.

Test model E[Yij] = µ + ai + bj + λ.ai.bj

H0: λ = 0, H1: λ != 0

From this test we see that p-value > 0.05 and so that additivity hypothesis cannot be rejected.

```{r warning=FALSE}
library(additivityTests)
Y=t(matrix(dat$nb_defects,nrow=4))
tukey.test(Y)
```

#### ii. We accept the additive model. How to estimate E[Yi,j] in this model?

```{r}
summary(LM)
```

E[Yi,j] = μ + ai + bj
with 
- μ = (Intercept) = 22
- ai = estimate for Team
- bi = estimate for Workstation

ex: E[Y (for team="morning" and Workstation="C")] = 22 + 3 + 8 = 33 -> observed value = 35

```{r}
cbind(dat,predict(LM))
```


#### iii. Is the variable team influent?

```{r}
anova(LM)
```

p-value > 0.05: we do not reject H0, all ai can be considered equals -> no influence of Team variable

#### iv. Is the variable work station influent?

```{r}
anova(LM)
```

p-value < 0.05: we reject H0, all ai cannot be considered equals -> there is an influence of Workstation variable